{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1c0a89-3d99-4c89-95ae-6fd2c3f6a9ac",
   "metadata": {},
   "source": [
    "# Oil & Gas Synthetic Data Exploration\n",
    "\n",
    "This notebook explores the comprehensive synthetic datasets generated for oil and gas company dashboards.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The synthetic data includes:\n",
    "1. **Geospatial Dataset**: Oil wells, refineries, and facilities with production metrics\n",
    "2. **Time Series Datasets**: Production trends, pricing, demand forecasting, maintenance, and weather data\n",
    "\n",
    "**Project**: oil_gas_dashboards  \n",
    "**Data Quality Score**: 0.892  \n",
    "**MLflow Tracking**: http://localhost:8768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4f7ab-98f3-4a2f-8c12-d6ff1c7a1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Add scripts to path for data configuration\n",
    "sys.path.insert(0, '/mnt/code')\n",
    "from scripts.data_config import get_data_paths\n",
    "\n",
    "print(\"ğŸ“Š Oil & Gas Synthetic Data Exploration\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab54d71-fe89-4f5e-a78d-dd87c0b96a6e",
   "metadata": {},
   "source": [
    "## 1. Load Datasets\n",
    "\n",
    "Load all generated datasets using the proper data configuration paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b2c27-6a1a-4ba2-8ee4-97a3e3d1f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correct data paths\n",
    "project_name = 'oil_gas_dashboards'\n",
    "paths = get_data_paths(project_name)\n",
    "data_dir = paths['base_data_path']\n",
    "artifacts_dir = paths['artifacts_path']\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Artifacts directory: {artifacts_dir}\")\n",
    "print(f\"Project type: {'Git-based' if paths['is_git_based'] else 'DFS-based'}\")\n",
    "\n",
    "# Load all datasets\n",
    "datasets = {}\n",
    "\n",
    "# Load geospatial data\n",
    "geospatial_path = data_dir / 'geospatial_facilities.parquet'\n",
    "if geospatial_path.exists():\n",
    "    datasets['geospatial'] = pd.read_parquet(geospatial_path)\n",
    "    print(f\"âœ… Loaded geospatial data: {len(datasets['geospatial']):,} facilities\")\n",
    "else:\n",
    "    print(f\"âŒ Geospatial data not found at {geospatial_path}\")\n",
    "\n",
    "# Load time series datasets\n",
    "time_series_files = [\n",
    "    'production_timeseries.parquet',\n",
    "    'prices_timeseries.parquet', \n",
    "    'demand_timeseries.parquet',\n",
    "    'maintenance_timeseries.parquet',\n",
    "    'weather_timeseries.parquet'\n",
    "]\n",
    "\n",
    "for file in time_series_files:\n",
    "    dataset_name = file.replace('_timeseries.parquet', '')\n",
    "    file_path = data_dir / file\n",
    "    \n",
    "    if file_path.exists():\n",
    "        datasets[dataset_name] = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Convert date columns to datetime if needed\n",
    "        if 'date' in datasets[dataset_name].columns:\n",
    "            datasets[dataset_name]['date'] = pd.to_datetime(datasets[dataset_name]['date'])\n",
    "        \n",
    "        print(f\"âœ… Loaded {dataset_name} data: {len(datasets[dataset_name]):,} records\")\n",
    "    else:\n",
    "        print(f\"âŒ {dataset_name} data not found at {file_path}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Total datasets loaded: {len(datasets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ee3a6-74e4-44dd-918a-cc5c5b54cb01",
   "metadata": {},
   "source": [
    "## 2. Geospatial Facilities Analysis\n",
    "\n",
    "Explore the geographic distribution of oil and gas facilities worldwide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24dc77-e10e-465e-8bf5-d9e3b7b3c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'geospatial' in datasets:\n",
    "    geo_df = datasets['geospatial']\n",
    "    \n",
    "    print(\"ğŸŒ Geospatial Dataset Overview\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total facilities: {len(geo_df):,}\")\n",
    "    print(f\"Regions covered: {geo_df['region'].nunique()}\")\n",
    "    print(f\"Countries covered: {geo_df['country'].nunique()}\")\n",
    "    print(f\"Date range: {pd.Timestamp.now().strftime('%Y-%m-%d')}\")\n",
    "    print()\n",
    "    \n",
    "    # Facility type breakdown\n",
    "    print(\"ğŸ“Š Facility Type Distribution:\")\n",
    "    facility_counts = geo_df['facility_type'].value_counts()\n",
    "    for facility_type, count in facility_counts.items():\n",
    "        percentage = (count / len(geo_df)) * 100\n",
    "        print(f\"  {facility_type}: {count:,} ({percentage:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Regional distribution\n",
    "    print(\"ğŸ—ºï¸ Regional Distribution:\")\n",
    "    regional_counts = geo_df['region'].value_counts()\n",
    "    for region, count in regional_counts.items():\n",
    "        percentage = (count / len(geo_df)) * 100\n",
    "        print(f\"  {region}: {count:,} ({percentage:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Status analysis\n",
    "    print(\"âš¡ Facility Status:\")\n",
    "    status_counts = geo_df['status'].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        percentage = (count / len(geo_df)) * 100\n",
    "        print(f\"  {status}: {count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad4e45-8234-4a8b-9b87-20c925c9e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for geospatial data\n",
    "if 'geospatial' in datasets:\n",
    "    geo_df = datasets['geospatial']\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Facility types pie chart\n",
    "    facility_counts = geo_df['facility_type'].value_counts()\n",
    "    axes[0, 0].pie(facility_counts.values, labels=facility_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0, 0].set_title('Facility Type Distribution')\n",
    "    \n",
    "    # 2. Regional distribution bar chart\n",
    "    regional_counts = geo_df['region'].value_counts()\n",
    "    axes[0, 1].bar(range(len(regional_counts)), regional_counts.values)\n",
    "    axes[0, 1].set_title('Facilities by Region')\n",
    "    axes[0, 1].set_xlabel('Region')\n",
    "    axes[0, 1].set_ylabel('Number of Facilities')\n",
    "    axes[0, 1].set_xticks(range(len(regional_counts)))\n",
    "    axes[0, 1].set_xticklabels(regional_counts.index, rotation=45, ha='right')\n",
    "    \n",
    "    # 3. Oil production distribution (for oil wells only)\n",
    "    oil_wells = geo_df[geo_df['facility_type'] == 'oil_well']\n",
    "    if len(oil_wells) > 0 and 'oil_production_bpd' in oil_wells.columns:\n",
    "        axes[1, 0].hist(oil_wells['oil_production_bpd'], bins=50, alpha=0.7, edgecolor='black')\n",
    "        axes[1, 0].set_title('Oil Production Distribution (Wells)')\n",
    "        axes[1, 0].set_xlabel('Production (barrels/day)')\n",
    "        axes[1, 0].set_ylabel('Number of Wells')\n",
    "    \n",
    "    # 4. Equipment health score distribution\n",
    "    if 'equipment_health_score' in geo_df.columns:\n",
    "        axes[1, 1].hist(geo_df['equipment_health_score'], bins=30, alpha=0.7, edgecolor='black')\n",
    "        axes[1, 1].set_title('Equipment Health Score Distribution')\n",
    "        axes[1, 1].set_xlabel('Health Score')\n",
    "        axes[1, 1].set_ylabel('Number of Facilities')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1cc7e2-3c40-4e5a-8c8b-b8f48c6b1e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive world map of facilities\n",
    "if 'geospatial' in datasets:\n",
    "    geo_df = datasets['geospatial']\n",
    "    \n",
    "    # Create interactive map with plotly\n",
    "    fig = px.scatter_mapbox(\n",
    "        geo_df.sample(min(500, len(geo_df))),  # Limit to 500 points for performance\n",
    "        lat=\"latitude\",\n",
    "        lon=\"longitude\",\n",
    "        color=\"facility_type\",\n",
    "        size=\"oil_production_bpd\" if 'oil_production_bpd' in geo_df.columns else None,\n",
    "        hover_data=[\"facility_name\", \"region\", \"country\", \"status\"],\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        zoom=1,\n",
    "        title=\"Oil & Gas Facilities Worldwide\",\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":40,\"l\":0,\"b\":0})\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"ğŸ“ Map shows sample of {min(500, len(geo_df))} facilities from {len(geo_df)} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e0b34-9a2f-4c72-8f8a-6e3a1f4e27b9",
   "metadata": {},
   "source": [
    "## 3. Production Time Series Analysis\n",
    "\n",
    "Analyze oil and gas production trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a44b6-c1c9-4b71-85ad-7b7e3a71dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'production' in datasets:\n",
    "    prod_df = datasets['production']\n",
    "    \n",
    "    print(\"ğŸ›¢ï¸ Production Dataset Overview\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total records: {len(prod_df):,}\")\n",
    "    print(f\"Date range: {prod_df['date'].min().strftime('%Y-%m-%d')} to {prod_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Unique wells: {prod_df['facility_id'].nunique():,}\")\n",
    "    print(f\"Regions: {prod_df['region'].nunique()}\")\n",
    "    print()\n",
    "    \n",
    "    # Aggregate daily production by region\n",
    "    daily_production = prod_df.groupby(['date', 'region']).agg({\n",
    "        'oil_production_bpd': 'sum',\n",
    "        'gas_production_mcfd': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(\"ğŸ“ˆ Average Daily Production by Region:\")\n",
    "    regional_avg = prod_df.groupby('region').agg({\n",
    "        'oil_production_bpd': 'mean',\n",
    "        'gas_production_mcfd': 'mean'\n",
    "    }).round(0)\n",
    "    \n",
    "    for region in regional_avg.index:\n",
    "        oil_avg = regional_avg.loc[region, 'oil_production_bpd']\n",
    "        gas_avg = regional_avg.loc[region, 'gas_production_mcfd']\n",
    "        print(f\"  {region}: Oil {oil_avg:,.0f} bpd, Gas {gas_avg:,.0f} mcfd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44e35e-1549-4a0e-b22e-4e4a2f25b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production time series visualizations\n",
    "if 'production' in datasets:\n",
    "    prod_df = datasets['production']\n",
    "    \n",
    "    # Aggregate monthly production\n",
    "    prod_df['year_month'] = prod_df['date'].dt.to_period('M')\n",
    "    monthly_prod = prod_df.groupby(['year_month', 'region']).agg({\n",
    "        'oil_production_bpd': 'sum',\n",
    "        'gas_production_mcfd': 'sum'\n",
    "    }).reset_index()\n",
    "    monthly_prod['year_month'] = monthly_prod['year_month'].dt.to_timestamp()\n",
    "    \n",
    "    # Create subplots for oil and gas production\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=('Monthly Oil Production by Region', 'Monthly Gas Production by Region'),\n",
    "        vertical_spacing=0.08\n",
    "    )\n",
    "    \n",
    "    # Oil production by region\n",
    "    for region in monthly_prod['region'].unique():\n",
    "        region_data = monthly_prod[monthly_prod['region'] == region]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=region_data['year_month'],\n",
    "                y=region_data['oil_production_bpd'],\n",
    "                mode='lines+markers',\n",
    "                name=f'{region} Oil',\n",
    "                line=dict(width=2)\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Gas production by region\n",
    "    for region in monthly_prod['region'].unique():\n",
    "        region_data = monthly_prod[monthly_prod['region'] == region]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=region_data['year_month'],\n",
    "                y=region_data['gas_production_mcfd'],\n",
    "                mode='lines+markers',\n",
    "                name=f'{region} Gas',\n",
    "                line=dict(width=2),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Oil Production (bpd)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Gas Production (mcfd)\", row=2, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"Production Trends by Region\",\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e7e3f-a7a4-425c-b6b0-4f37e7b1b0c8",
   "metadata": {},
   "source": [
    "## 4. Price Analysis\n",
    "\n",
    "Examine oil and gas price trends and volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1e4a0-54e1-4950-a44b-a1e7b73e3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'prices' in datasets:\n",
    "    price_df = datasets['prices']\n",
    "    \n",
    "    print(\"ğŸ’° Price Dataset Overview\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total records: {len(price_df):,}\")\n",
    "    print(f\"Date range: {price_df['date'].min().strftime('%Y-%m-%d')} to {price_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate price statistics\n",
    "    price_columns = [col for col in price_df.columns if 'price' in col.lower()]\n",
    "    \n",
    "    print(\"ğŸ“Š Price Statistics (USD):\")\n",
    "    for col in price_columns:\n",
    "        avg_price = price_df[col].mean()\n",
    "        min_price = price_df[col].min()\n",
    "        max_price = price_df[col].max()\n",
    "        volatility = price_df[col].std()\n",
    "        \n",
    "        product = col.replace('_price_usd_', ' ').replace('_', ' ').title()\n",
    "        print(f\"  {product}: Avg ${avg_price:.2f}, Range ${min_price:.2f}-${max_price:.2f}, Volatility ${volatility:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067f2b0-3b41-4098-b1e1-d7e6bb7ee2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price trends visualization\n",
    "if 'prices' in datasets:\n",
    "    price_df = datasets['prices']\n",
    "    \n",
    "    # Create interactive price chart\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=('Crude Oil Prices', 'Refined Product Prices'),\n",
    "        vertical_spacing=0.08\n",
    "    )\n",
    "    \n",
    "    # Crude oil prices\n",
    "    oil_price_cols = ['crude_oil_price_usd_bbl', 'brent_crude_usd_bbl', 'wti_crude_usd_bbl']\n",
    "    for col in oil_price_cols:\n",
    "        if col in price_df.columns:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=price_df['date'],\n",
    "                    y=price_df[col],\n",
    "                    mode='lines',\n",
    "                    name=col.replace('_', ' ').title().replace('Usd', 'USD'),\n",
    "                    line=dict(width=2)\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "    \n",
    "    # Refined product prices\n",
    "    product_price_cols = ['gasoline_price_usd_gal', 'diesel_price_usd_gal', 'jet_fuel_price_usd_gal']\n",
    "    for col in product_price_cols:\n",
    "        if col in price_df.columns:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=price_df['date'],\n",
    "                    y=price_df[col],\n",
    "                    mode='lines',\n",
    "                    name=col.replace('_', ' ').title().replace('Usd', 'USD'),\n",
    "                    line=dict(width=2),\n",
    "                    showlegend=True\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price (USD/barrel)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price (USD/gallon)\", row=2, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"Oil and Gas Price Trends\",\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8c63a-7c0a-4a48-b5ad-95e92e3f22c8",
   "metadata": {},
   "source": [
    "## 5. Demand Forecasting Analysis\n",
    "\n",
    "Examine regional demand patterns and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1d26c-1a75-4b66-9a34-9c5b6e3c8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'demand' in datasets:\n",
    "    demand_df = datasets['demand']\n",
    "    \n",
    "    print(\"ğŸ“Š Demand Dataset Overview\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total records: {len(demand_df):,}\")\n",
    "    print(f\"Date range: {demand_df['date'].min().strftime('%Y-%m-%d')} to {demand_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Regions: {demand_df['region'].nunique()}\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate average demand by region\n",
    "    avg_demand = demand_df.groupby('region').agg({\n",
    "        'oil_demand_thousand_bpd': 'mean',\n",
    "        'gas_demand_thousand_mcfd': 'mean',\n",
    "        'gasoline_demand_thousand_bpd': 'mean',\n",
    "        'diesel_demand_thousand_bpd': 'mean'\n",
    "    }).round(1)\n",
    "    \n",
    "    print(\"ğŸ“ˆ Average Daily Demand by Region (thousands):\")\n",
    "    for region in avg_demand.index:\n",
    "        oil = avg_demand.loc[region, 'oil_demand_thousand_bpd']\n",
    "        gas = avg_demand.loc[region, 'gas_demand_thousand_mcfd']\n",
    "        gasoline = avg_demand.loc[region, 'gasoline_demand_thousand_bpd']\n",
    "        diesel = avg_demand.loc[region, 'diesel_demand_thousand_bpd']\n",
    "        print(f\"  {region}:\")\n",
    "        print(f\"    Oil: {oil:,.1f}k bpd, Gas: {gas:,.1f}k mcfd\")\n",
    "        print(f\"    Gasoline: {gasoline:,.1f}k bpd, Diesel: {diesel:,.1f}k bpd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a82850-62db-4b8d-b3d5-0a09b0c8ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demand trends visualization\n",
    "if 'demand' in datasets:\n",
    "    demand_df = datasets['demand']\n",
    "    \n",
    "    # Aggregate monthly demand\n",
    "    demand_df['year_month'] = demand_df['date'].dt.to_period('M')\n",
    "    monthly_demand = demand_df.groupby(['year_month', 'region']).agg({\n",
    "        'oil_demand_thousand_bpd': 'mean',\n",
    "        'gas_demand_thousand_mcfd': 'mean'\n",
    "    }).reset_index()\n",
    "    monthly_demand['year_month'] = monthly_demand['year_month'].dt.to_timestamp()\n",
    "    \n",
    "    # Create demand trend visualization\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=('Oil Demand by Region', 'Gas Demand by Region'),\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # Oil demand\n",
    "    for region in monthly_demand['region'].unique():\n",
    "        region_data = monthly_demand[monthly_demand['region'] == region]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=region_data['year_month'],\n",
    "                y=region_data['oil_demand_thousand_bpd'],\n",
    "                mode='lines+markers',\n",
    "                name=f'{region}',\n",
    "                line=dict(width=2)\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Gas demand\n",
    "    for region in monthly_demand['region'].unique():\n",
    "        region_data = monthly_demand[monthly_demand['region'] == region]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=region_data['year_month'],\n",
    "                y=region_data['gas_demand_thousand_mcfd'],\n",
    "                mode='lines+markers',\n",
    "                name=f'{region} Gas',\n",
    "                line=dict(width=2),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Date\")\n",
    "    fig.update_yaxes(title_text=\"Oil Demand (thousand bpd)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Gas Demand (thousand mcfd)\", row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        title_text=\"Regional Demand Trends\",\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e5c4c-8a63-4f40-9c56-9a524a0d2e8c",
   "metadata": {},
   "source": [
    "## 6. Maintenance Analysis\n",
    "\n",
    "Examine equipment maintenance patterns and costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec6cf1-e847-4e5d-9c83-4deca1c6eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'maintenance' in datasets:\n",
    "    maint_df = datasets['maintenance']\n",
    "    \n",
    "    print(\"ğŸ”§ Maintenance Dataset Overview\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total maintenance events: {len(maint_df):,}\")\n",
    "    print(f\"Date range: {maint_df['date'].min().strftime('%Y-%m-%d')} to {maint_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Unique facilities: {maint_df['facility_id'].nunique():,}\")\n",
    "    print()\n",
    "    \n",
    "    # Maintenance type analysis\n",
    "    print(\"ğŸ› ï¸ Maintenance Type Distribution:\")\n",
    "    maint_types = maint_df['maintenance_type'].value_counts()\n",
    "    total_cost = maint_df['cost_usd'].sum()\n",
    "    \n",
    "    for mtype, count in maint_types.items():\n",
    "        percentage = (count / len(maint_df)) * 100\n",
    "        type_cost = maint_df[maint_df['maintenance_type'] == mtype]['cost_usd'].sum()\n",
    "        cost_percentage = (type_cost / total_cost) * 100\n",
    "        avg_cost = maint_df[maint_df['maintenance_type'] == mtype]['cost_usd'].mean()\n",
    "        print(f\"  {mtype}: {count:,} events ({percentage:.1f}%), Avg cost: ${avg_cost:,.0f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’° Total maintenance cost: ${total_cost:,.0f}\")\n",
    "    print(f\"ğŸ“… Average cost per day: ${total_cost / len(maint_df['date'].unique()):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8f26a-3ce5-4c2e-be01-3b5b09a3fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintenance analysis visualizations\n",
    "if 'maintenance' in datasets:\n",
    "    maint_df = datasets['maintenance']\n",
    "    \n",
    "    # Create maintenance analysis plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Maintenance type distribution\n",
    "    maint_types = maint_df['maintenance_type'].value_counts()\n",
    "    axes[0, 0].pie(maint_types.values, labels=maint_types.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0, 0].set_title('Maintenance Type Distribution')\n",
    "    \n",
    "    # 2. Cost by maintenance type\n",
    "    cost_by_type = maint_df.groupby('maintenance_type')['cost_usd'].sum().sort_values(ascending=False)\n",
    "    axes[0, 1].bar(range(len(cost_by_type)), cost_by_type.values)\n",
    "    axes[0, 1].set_title('Total Maintenance Cost by Type')\n",
    "    axes[0, 1].set_xlabel('Maintenance Type')\n",
    "    axes[0, 1].set_ylabel('Total Cost (USD)')\n",
    "    axes[0, 1].set_xticks(range(len(cost_by_type)))\n",
    "    axes[0, 1].set_xticklabels(cost_by_type.index, rotation=45, ha='right')\n",
    "    \n",
    "    # 3. Duration distribution\n",
    "    axes[1, 0].hist(maint_df['duration_hours'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_title('Maintenance Duration Distribution')\n",
    "    axes[1, 0].set_xlabel('Duration (hours)')\n",
    "    axes[1, 0].set_ylabel('Number of Events')\n",
    "    \n",
    "    # 4. Cost distribution\n",
    "    axes[1, 1].hist(maint_df['cost_usd'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 1].set_title('Maintenance Cost Distribution')\n",
    "    axes[1, 1].set_xlabel('Cost (USD)')\n",
    "    axes[1, 1].set_ylabel('Number of Events')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7b4bc-5d27-4e5c-8c33-85f4cdc8fbc9",
   "metadata": {},
   "source": [
    "## 7. Weather Impact Analysis\n",
    "\n",
    "Examine weather conditions and their impact on operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b924068-e36c-4b01-b43e-a55ef33f2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'weather' in datasets:\n",
    "    weather_df = datasets['weather']\n",
    "    \n",
    "    print(\"ğŸŒ¤ï¸ Weather Dataset Overview\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total records: {len(weather_df):,}\")\n",
    "    print(f\"Date range: {weather_df['date'].min().strftime('%Y-%m-%d')} to {weather_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Regions: {weather_df['region'].nunique()}\")\n",
    "    print()\n",
    "    \n",
    "    # Weather condition analysis\n",
    "    print(\"ğŸŒ¦ï¸ Weather Condition Distribution:\")\n",
    "    weather_conditions = weather_df['weather_condition'].value_counts()\n",
    "    for condition, count in weather_conditions.items():\n",
    "        percentage = (count / len(weather_df)) * 100\n",
    "        avg_impact = weather_df[weather_df['weather_condition'] == condition]['operation_impact_score'].mean()\n",
    "        print(f\"  {condition}: {count:,} days ({percentage:.1f}%), Avg impact: {avg_impact:.3f}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Regional climate summary\n",
    "    print(\"ğŸŒ¡ï¸ Regional Climate Summary:\")\n",
    "    climate_summary = weather_df.groupby('region').agg({\n",
    "        'temperature_celsius': ['mean', 'min', 'max'],\n",
    "        'humidity_percent': 'mean',\n",
    "        'precipitation_mm': 'mean',\n",
    "        'operation_impact_score': 'mean'\n",
    "    }).round(1)\n",
    "    \n",
    "    for region in climate_summary.index:\n",
    "        temp_avg = climate_summary.loc[region, ('temperature_celsius', 'mean')]\n",
    "        temp_min = climate_summary.loc[region, ('temperature_celsius', 'min')]\n",
    "        temp_max = climate_summary.loc[region, ('temperature_celsius', 'max')]\n",
    "        humidity = climate_summary.loc[region, ('humidity_percent', 'mean')]\n",
    "        precipitation = climate_summary.loc[region, ('precipitation_mm', 'mean')]\n",
    "        impact = climate_summary.loc[region, ('operation_impact_score', 'mean')]\n",
    "        \n",
    "        print(f\"  {region}:\")\n",
    "        print(f\"    Temperature: {temp_avg:.1f}Â°C (range: {temp_min:.1f}Â°C to {temp_max:.1f}Â°C)\")\n",
    "        print(f\"    Humidity: {humidity:.1f}%, Precipitation: {precipitation:.1f}mm/day\")\n",
    "        print(f\"    Operation impact: {impact:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a2d2e-8b8f-40b5-a3e1-f86bb1c8a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather impact visualization\n",
    "if 'weather' in datasets:\n",
    "    weather_df = datasets['weather']\n",
    "    \n",
    "    # Monthly temperature trends by region\n",
    "    weather_df['year_month'] = weather_df['date'].dt.to_period('M')\n",
    "    monthly_weather = weather_df.groupby(['year_month', 'region']).agg({\n",
    "        'temperature_celsius': 'mean',\n",
    "        'operation_impact_score': 'mean'\n",
    "    }).reset_index()\n",
    "    monthly_weather['year_month'] = monthly_weather['year_month'].dt.to_timestamp()\n",
    "    \n",
    "    # Create temperature trends chart\n",
    "    fig = px.line(\n",
    "        monthly_weather,\n",
    "        x='year_month',\n",
    "        y='temperature_celsius',\n",
    "        color='region',\n",
    "        title='Monthly Temperature Trends by Region',\n",
    "        labels={'temperature_celsius': 'Temperature (Â°C)', 'year_month': 'Date'},\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(hovermode='x unified')\n",
    "    fig.show()\n",
    "    \n",
    "    # Operation impact vs weather conditions\n",
    "    fig = px.box(\n",
    "        weather_df,\n",
    "        x='weather_condition',\n",
    "        y='operation_impact_score',\n",
    "        title='Operation Impact by Weather Condition',\n",
    "        labels={'operation_impact_score': 'Operation Impact Score', 'weather_condition': 'Weather Condition'},\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff3dde-78fe-4a5c-9f1d-de3528d0fdfc",
   "metadata": {},
   "source": [
    "## 8. Data Quality Assessment\n",
    "\n",
    "Review the quality and completeness of generated datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9dd8c4-3b99-4b91-bf71-68db23f1ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data quality summary from generation\n",
    "summary_path = artifacts_dir / 'reports' / 'data_generation_summary.json'\n",
    "\n",
    "if summary_path.exists():\n",
    "    with open(summary_path, 'r') as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"âœ… Data Quality Assessment\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Generation Date: {summary['generation_date']}\")\n",
    "    print(f\"Overall Quality Score: {summary['overall_quality']:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"ğŸ“Š Dataset Quality Scores:\")\n",
    "    for dataset, score in summary['quality_scores'].items():\n",
    "        status = \"âœ… Excellent\" if score >= 0.9 else \"âš ï¸ Good\" if score >= 0.7 else \"âŒ Needs Review\"\n",
    "        print(f\"  {dataset}: {score:.3f} {status}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸ“ˆ Dataset Statistics:\")\n",
    "    print(f\"  Total facilities: {summary['total_facilities']:,}\")\n",
    "    \n",
    "    facility_breakdown = summary['facility_breakdown']\n",
    "    print(\"  Facility breakdown:\")\n",
    "    for facility_type, count in facility_breakdown.items():\n",
    "        print(f\"    {facility_type}: {count:,}\")\n",
    "    \n",
    "    print(f\"  Regions covered: {', '.join(summary['regions_covered'])}\")\n",
    "    print(f\"  Time series datasets: {', '.join(summary['time_series_datasets'])}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Data generation summary not found\")\n",
    "\n",
    "# Additional quality checks on loaded datasets\n",
    "print(\"\\nğŸ” Additional Data Quality Checks:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for dataset_name, df in datasets.items():\n",
    "    print(f\"\\n{dataset_name.title()} Dataset:\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing_count = df.isnull().sum().sum()\n",
    "    missing_percentage = (missing_count / (len(df) * len(df.columns))) * 100\n",
    "    print(f\"  Missing values: {missing_count:,} ({missing_percentage:.2f}%)\")\n",
    "    \n",
    "    # Duplicate records\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"  Duplicate records: {duplicates:,}\")\n",
    "    \n",
    "    # Data types\n",
    "    numeric_cols = len(df.select_dtypes(include=[np.number]).columns)\n",
    "    text_cols = len(df.select_dtypes(include=['object']).columns)\n",
    "    date_cols = len(df.select_dtypes(include=['datetime64']).columns)\n",
    "    print(f\"  Column types: {numeric_cols} numeric, {text_cols} text, {date_cols} datetime\")\n",
    "    \n",
    "    # Data range validation\n",
    "    if dataset_name == 'geospatial':\n",
    "        lat_range = (df['latitude'].min(), df['latitude'].max())\n",
    "        lon_range = (df['longitude'].min(), df['longitude'].max())\n",
    "        print(f\"  Geographic range: Lat {lat_range[0]:.2f} to {lat_range[1]:.2f}, Lon {lon_range[0]:.2f} to {lon_range[1]:.2f}\")\n",
    "    \n",
    "    elif 'date' in df.columns:\n",
    "        date_range = (df['date'].min().strftime('%Y-%m-%d'), df['date'].max().strftime('%Y-%m-%d'))\n",
    "        print(f\"  Date range: {date_range[0]} to {date_range[1]}\")\n",
    "        \n",
    "        # Check for data gaps in time series\n",
    "        expected_days = (df['date'].max() - df['date'].min()).days + 1\n",
    "        unique_days = df['date'].nunique()\n",
    "        if dataset_name in ['production', 'prices', 'weather', 'demand']:\n",
    "            completeness = (unique_days / expected_days) * 100\n",
    "            print(f\"  Temporal completeness: {completeness:.1f}% ({unique_days}/{expected_days} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8e3dd-3d74-4e8c-927c-e4e5e70ea73b",
   "metadata": {},
   "source": [
    "## 9. Summary and Recommendations\n",
    "\n",
    "Summary of generated datasets and recommendations for dashboard development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456a8fb-edb5-4a18-95f2-49e4e8a51bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ Synthetic Data Generation Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"âœ… Successfully Generated Datasets:\")\n",
    "total_records = sum(len(df) for df in datasets.values())\n",
    "print(f\"  Total records across all datasets: {total_records:,}\")\n",
    "\n",
    "for dataset_name, df in datasets.items():\n",
    "    print(f\"  {dataset_name.title()}: {len(df):,} records, {len(df.columns)} columns\")\n",
    "\n",
    "if 'geospatial' in datasets:\n",
    "    geo_df = datasets['geospatial']\n",
    "    print(f\"\\nğŸŒ Geographic Coverage:\")\n",
    "    print(f\"  {geo_df['region'].nunique()} regions: {', '.join(geo_df['region'].unique())}\")\n",
    "    print(f\"  {geo_df['country'].nunique()} countries\")\n",
    "    print(f\"  {len(geo_df)} facilities total\")\n",
    "\n",
    "if any('date' in df.columns for df in datasets.values()):\n",
    "    time_series_datasets = [name for name, df in datasets.items() if 'date' in df.columns]\n",
    "    date_ranges = [(datasets[name]['date'].min(), datasets[name]['date'].max()) for name in time_series_datasets]\n",
    "    overall_start = min(dr[0] for dr in date_ranges)\n",
    "    overall_end = max(dr[1] for dr in date_ranges)\n",
    "    \n",
    "    print(f\"\\nğŸ“… Temporal Coverage:\")\n",
    "    print(f\"  Date range: {overall_start.strftime('%Y-%m-%d')} to {overall_end.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Duration: {(overall_end - overall_start).days} days\")\n",
    "    print(f\"  Time series datasets: {len(time_series_datasets)}\")\n",
    "\n",
    "print(\"\\nğŸ¯ Dashboard Development Recommendations:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "recommendations = [\n",
    "    \"ğŸ—ºï¸ **Geospatial Dashboard**: Create interactive maps showing facility locations, production levels, and equipment health\",\n",
    "    \"ğŸ“Š **Production Dashboard**: Build time series visualizations for oil/gas production trends by region and facility\",\n",
    "    \"ğŸ’° **Financial Dashboard**: Develop price tracking and revenue analytics using price and production data\", \n",
    "    \"ğŸ“ˆ **Demand Forecasting**: Create predictive analytics dashboard using demand patterns and historical trends\",\n",
    "    \"ğŸ”§ **Maintenance Dashboard**: Build maintenance scheduling and cost optimization tools\",\n",
    "    \"ğŸŒ¤ï¸ **Operations Weather Dashboard**: Create weather impact analysis and operational risk assessment\",\n",
    "    \"ğŸš¨ **Alert System**: Implement real-time monitoring for equipment health, production anomalies, and extreme weather\",\n",
    "    \"ğŸ“‹ **Executive Summary**: Build high-level KPI dashboard combining all data sources for leadership overview\"\n",
    "]\n",
    "\n",
    "for i, recommendation in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {recommendation}\")\n",
    "\n",
    "print(\"\\nğŸ› ï¸ Technical Integration Points:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"â€¢ Use Plotly/Dash for interactive Python dashboards\")\n",
    "print(\"â€¢ Implement real-time data refresh using Domino scheduled jobs\")\n",
    "print(\"â€¢ Deploy as Domino Apps for enterprise access\")\n",
    "print(\"â€¢ Use MLflow for model tracking and deployment\")\n",
    "print(\"â€¢ Implement data quality monitoring and alerting\")\n",
    "print(\"â€¢ Create API endpoints for dashboard data serving\")\n",
    "\n",
    "print(\"\\nğŸ“ File Locations:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"ğŸ“‚ Data: {data_dir}\")\n",
    "print(f\"ğŸ“‚ Artifacts: {artifacts_dir}\")\n",
    "print(f\"ğŸ“‚ Notebooks: /mnt/code/notebooks/\")\n",
    "print(f\"ğŸ“‚ Scripts: /mnt/code/scripts/\")\n",
    "print(f\"ğŸŒ MLflow UI: http://localhost:8768\")\n",
    "\n",
    "print(\"\\nâœ¨ Data generation completed successfully!\")\n",
    "print(\"Ready for dashboard development and deployment on Domino Data Lab platform.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}